{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yashv\\Downloads\\HADLN_implementation\\HADLN_implementation\\notebooks\n",
      "C:\\Users\\yashv\\Downloads\\HADLN_implementation\\HADLN_implementation\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Check current working directory\n",
    "print(os.getcwd())\n",
    "\n",
    "# Change to the root directory of your project, if necessary\n",
    "os.chdir('C:/Users/yashv/Downloads/HADLN_implementation/HADLN_implementation/')\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yashv\\.conda\\envs\\tf\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 2000, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 2000, 32)     544         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 2000, 32)    128         ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 2000, 32)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 2000, 32)     16416       ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 2000, 32)     64          ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 2000, 32)    128         ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 2000, 32)    128         ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 2000, 32)     0           ['batch_normalization_1[0][0]',  \n",
      "                                                                  'batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 2000, 32)     0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 2000, 1)      33          ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " tf.nn.softmax (TFOpLambda)     (None, 2000, 1)      0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " multiply (Multiply)            (None, 2000, 32)     0           ['activation_1[0][0]',           \n",
      "                                                                  'tf.nn.softmax[0][0]']          \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 2000, 32)     0           ['multiply[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 2000, 32)     16416       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 2000, 32)    128         ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 2000, 32)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 2000, 32)     16416       ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 2000, 32)     1056        ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 2000, 32)    128         ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 2000, 32)    128         ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 2000, 32)     0           ['batch_normalization_4[0][0]',  \n",
      "                                                                  'batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 2000, 32)     0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 2000, 1)      33          ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " tf.nn.softmax_1 (TFOpLambda)   (None, 2000, 1)      0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " multiply_1 (Multiply)          (None, 2000, 32)     0           ['activation_3[0][0]',           \n",
      "                                                                  'tf.nn.softmax_1[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 2000, 32)     0           ['multiply_1[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 2000, 32)     16416       ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 2000, 32)    128         ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 2000, 32)     0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 2000, 32)     16416       ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_8 (Conv1D)              (None, 2000, 32)     1056        ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 2000, 32)    128         ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 2000, 32)    128         ['conv1d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 2000, 32)     0           ['batch_normalization_7[0][0]',  \n",
      "                                                                  'batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 2000, 32)     0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 2000, 1)      33          ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " tf.nn.softmax_2 (TFOpLambda)   (None, 2000, 1)      0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " multiply_2 (Multiply)          (None, 2000, 32)     0           ['activation_5[0][0]',           \n",
      "                                                                  'tf.nn.softmax_2[0][0]']        \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 1000, 32)     0           ['multiply_2[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 1000, 32)     0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_9 (Conv1D)              (None, 1000, 64)     32832       ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 1000, 64)    256         ['conv1d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 1000, 64)     0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_10 (Conv1D)             (None, 1000, 64)     65600       ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_11 (Conv1D)             (None, 1000, 64)     2112        ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 1000, 64)    256         ['conv1d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 1000, 64)    256         ['conv1d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 1000, 64)     0           ['batch_normalization_10[0][0]', \n",
      "                                                                  'batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 1000, 64)     0           ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 1000, 1)      65          ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " tf.nn.softmax_3 (TFOpLambda)   (None, 1000, 1)      0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " multiply_3 (Multiply)          (None, 1000, 64)     0           ['activation_7[0][0]',           \n",
      "                                                                  'tf.nn.softmax_3[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 1000, 64)     0           ['multiply_3[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_12 (Conv1D)             (None, 1000, 64)     65600       ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 1000, 64)    256         ['conv1d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 1000, 64)     0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_13 (Conv1D)             (None, 1000, 64)     65600       ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_14 (Conv1D)             (None, 1000, 64)     4160        ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 1000, 64)    256         ['conv1d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 1000, 64)    256         ['conv1d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 1000, 64)     0           ['batch_normalization_13[0][0]', \n",
      "                                                                  'batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 1000, 64)     0           ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 1000, 1)      65          ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " tf.nn.softmax_4 (TFOpLambda)   (None, 1000, 1)      0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " multiply_4 (Multiply)          (None, 1000, 64)     0           ['activation_9[0][0]',           \n",
      "                                                                  'tf.nn.softmax_4[0][0]']        \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 500, 64)     0           ['multiply_4[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 500, 64)      0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_15 (Conv1D)             (None, 500, 64)      65600       ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 500, 64)     256         ['conv1d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 500, 64)      0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_16 (Conv1D)             (None, 500, 64)      65600       ['activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_17 (Conv1D)             (None, 500, 64)      4160        ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 500, 64)     256         ['conv1d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 500, 64)     256         ['conv1d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 500, 64)      0           ['batch_normalization_16[0][0]', \n",
      "                                                                  'batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 500, 64)      0           ['add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 500, 1)       65          ['activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " tf.nn.softmax_5 (TFOpLambda)   (None, 500, 1)       0           ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " multiply_5 (Multiply)          (None, 500, 64)      0           ['activation_11[0][0]',          \n",
      "                                                                  'tf.nn.softmax_5[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 500, 64)      0           ['multiply_5[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_18 (Conv1D)             (None, 500, 64)      65600       ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 500, 64)     256         ['conv1d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 500, 64)      0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_19 (Conv1D)             (None, 500, 64)      65600       ['activation_12[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_20 (Conv1D)             (None, 500, 64)      4160        ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 500, 64)     256         ['conv1d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 500, 64)     256         ['conv1d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 500, 64)      0           ['batch_normalization_19[0][0]', \n",
      "                                                                  'batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 500, 64)      0           ['add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 500, 1)       65          ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " tf.nn.softmax_6 (TFOpLambda)   (None, 500, 1)       0           ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " multiply_6 (Multiply)          (None, 500, 64)      0           ['activation_13[0][0]',          \n",
      "                                                                  'tf.nn.softmax_6[0][0]']        \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 250, 64)     0           ['multiply_6[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 250, 64)      0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_21 (Conv1D)             (None, 250, 128)     131200      ['dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 250, 128)    512         ['conv1d_21[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 250, 128)     0           ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_22 (Conv1D)             (None, 250, 128)     262272      ['activation_14[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_23 (Conv1D)             (None, 250, 128)     8320        ['dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 250, 128)    512         ['conv1d_22[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 250, 128)    512         ['conv1d_23[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 250, 128)     0           ['batch_normalization_22[0][0]', \n",
      "                                                                  'batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 250, 128)     0           ['add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 250, 1)       129         ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " tf.nn.softmax_7 (TFOpLambda)   (None, 250, 1)       0           ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " multiply_7 (Multiply)          (None, 250, 128)     0           ['activation_15[0][0]',          \n",
      "                                                                  'tf.nn.softmax_7[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 250, 128)     0           ['multiply_7[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_24 (Conv1D)             (None, 250, 128)     262272      ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 250, 128)    512         ['conv1d_24[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 250, 128)     0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_25 (Conv1D)             (None, 250, 128)     262272      ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_26 (Conv1D)             (None, 250, 128)     16512       ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 250, 128)    512         ['conv1d_25[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 250, 128)    512         ['conv1d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 250, 128)     0           ['batch_normalization_25[0][0]', \n",
      "                                                                  'batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 250, 128)     0           ['add_8[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 250, 1)       129         ['activation_17[0][0]']          \n",
      "                                                                                                  \n",
      " tf.nn.softmax_8 (TFOpLambda)   (None, 250, 1)       0           ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " multiply_8 (Multiply)          (None, 250, 128)     0           ['activation_17[0][0]',          \n",
      "                                                                  'tf.nn.softmax_8[0][0]']        \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 125, 128)    0           ['multiply_8[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 125, 128)     0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_27 (Conv1D)             (None, 125, 128)     262272      ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 125, 128)    512         ['conv1d_27[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 125, 128)     0           ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_28 (Conv1D)             (None, 125, 128)     262272      ['activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_29 (Conv1D)             (None, 125, 128)     16512       ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 125, 128)    512         ['conv1d_28[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 125, 128)    512         ['conv1d_29[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 125, 128)     0           ['batch_normalization_28[0][0]', \n",
      "                                                                  'batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 125, 128)     0           ['add_9[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 125, 1)       129         ['activation_19[0][0]']          \n",
      "                                                                                                  \n",
      " tf.nn.softmax_9 (TFOpLambda)   (None, 125, 1)       0           ['dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " multiply_9 (Multiply)          (None, 125, 128)     0           ['activation_19[0][0]',          \n",
      "                                                                  'tf.nn.softmax_9[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 125, 128)     0           ['multiply_9[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_30 (Conv1D)             (None, 125, 128)     262272      ['dropout_9[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 125, 128)    512         ['conv1d_30[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 125, 128)     0           ['batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_31 (Conv1D)             (None, 125, 128)     262272      ['activation_20[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_32 (Conv1D)             (None, 125, 128)     16512       ['dropout_9[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 125, 128)    512         ['conv1d_31[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 125, 128)    512         ['conv1d_32[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_10 (Add)                   (None, 125, 128)     0           ['batch_normalization_31[0][0]', \n",
      "                                                                  'batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 125, 128)     0           ['add_10[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 125, 1)       129         ['activation_21[0][0]']          \n",
      "                                                                                                  \n",
      " tf.nn.softmax_10 (TFOpLambda)  (None, 125, 1)       0           ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      " multiply_10 (Multiply)         (None, 125, 128)     0           ['activation_21[0][0]',          \n",
      "                                                                  'tf.nn.softmax_10[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 62, 128)     0           ['multiply_10[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)           (None, 62, 128)      0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_33 (Conv1D)             (None, 62, 256)      524544      ['dropout_10[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 62, 256)     1024        ['conv1d_33[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 62, 256)      0           ['batch_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_34 (Conv1D)             (None, 62, 256)      1048832     ['activation_22[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_35 (Conv1D)             (None, 62, 256)      33024       ['dropout_10[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 62, 256)     1024        ['conv1d_34[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 62, 256)     1024        ['conv1d_35[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, 62, 256)      0           ['batch_normalization_34[0][0]', \n",
      "                                                                  'batch_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 62, 256)      0           ['add_11[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 62, 1)        257         ['activation_23[0][0]']          \n",
      "                                                                                                  \n",
      " tf.nn.softmax_11 (TFOpLambda)  (None, 62, 1)        0           ['dense_11[0][0]']               \n",
      "                                                                                                  \n",
      " multiply_11 (Multiply)         (None, 62, 256)      0           ['activation_23[0][0]',          \n",
      "                                                                  'tf.nn.softmax_11[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)           (None, 62, 256)      0           ['multiply_11[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_36 (Conv1D)             (None, 62, 256)      1048832     ['dropout_11[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 62, 256)     1024        ['conv1d_36[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 62, 256)      0           ['batch_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_37 (Conv1D)             (None, 62, 256)      1048832     ['activation_24[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_38 (Conv1D)             (None, 62, 256)      65792       ['dropout_11[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 62, 256)     1024        ['conv1d_37[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 62, 256)     1024        ['conv1d_38[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_12 (Add)                   (None, 62, 256)      0           ['batch_normalization_37[0][0]', \n",
      "                                                                  'batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 62, 256)      0           ['add_12[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 62, 1)        257         ['activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " tf.nn.softmax_12 (TFOpLambda)  (None, 62, 1)        0           ['dense_12[0][0]']               \n",
      "                                                                                                  \n",
      " multiply_12 (Multiply)         (None, 62, 256)      0           ['activation_25[0][0]',          \n",
      "                                                                  'tf.nn.softmax_12[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 31, 256)     0           ['multiply_12[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)           (None, 31, 256)      0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_39 (Conv1D)             (None, 31, 256)      1048832     ['dropout_12[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 31, 256)     1024        ['conv1d_39[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 31, 256)      0           ['batch_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_40 (Conv1D)             (None, 31, 256)      1048832     ['activation_26[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_41 (Conv1D)             (None, 31, 256)      65792       ['dropout_12[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 31, 256)     1024        ['conv1d_40[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 31, 256)     1024        ['conv1d_41[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_13 (Add)                   (None, 31, 256)      0           ['batch_normalization_40[0][0]', \n",
      "                                                                  'batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 31, 256)      0           ['add_13[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 31, 1)        257         ['activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " tf.nn.softmax_13 (TFOpLambda)  (None, 31, 1)        0           ['dense_13[0][0]']               \n",
      "                                                                                                  \n",
      " multiply_13 (Multiply)         (None, 31, 256)      0           ['activation_27[0][0]',          \n",
      "                                                                  'tf.nn.softmax_13[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)           (None, 31, 256)      0           ['multiply_13[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_42 (Conv1D)             (None, 31, 256)      1048832     ['dropout_13[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 31, 256)     1024        ['conv1d_42[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 31, 256)      0           ['batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_43 (Conv1D)             (None, 31, 256)      1048832     ['activation_28[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_44 (Conv1D)             (None, 31, 256)      65792       ['dropout_13[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 31, 256)     1024        ['conv1d_43[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 31, 256)     1024        ['conv1d_44[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_14 (Add)                   (None, 31, 256)      0           ['batch_normalization_43[0][0]', \n",
      "                                                                  'batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 31, 256)      0           ['add_14[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 31, 1)        257         ['activation_29[0][0]']          \n",
      "                                                                                                  \n",
      " tf.nn.softmax_14 (TFOpLambda)  (None, 31, 1)        0           ['dense_14[0][0]']               \n",
      "                                                                                                  \n",
      " multiply_14 (Multiply)         (None, 31, 256)      0           ['activation_29[0][0]',          \n",
      "                                                                  'tf.nn.softmax_14[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 15, 256)     0           ['multiply_14[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_14 (Dropout)           (None, 15, 256)      0           ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_45 (Conv1D)             (None, 15, 256)      1048832     ['dropout_14[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 15, 256)     1024        ['conv1d_45[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 15, 256)      0           ['batch_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_46 (Conv1D)             (None, 15, 256)      1048832     ['activation_30[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_47 (Conv1D)             (None, 15, 256)      65792       ['dropout_14[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 15, 256)     1024        ['conv1d_46[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 15, 256)     1024        ['conv1d_47[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_15 (Add)                   (None, 15, 256)      0           ['batch_normalization_46[0][0]', \n",
      "                                                                  'batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 15, 256)      0           ['add_15[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 15, 1)        257         ['activation_31[0][0]']          \n",
      "                                                                                                  \n",
      " tf.nn.softmax_15 (TFOpLambda)  (None, 15, 1)        0           ['dense_15[0][0]']               \n",
      "                                                                                                  \n",
      " multiply_15 (Multiply)         (None, 15, 256)      0           ['activation_31[0][0]',          \n",
      "                                                                  'tf.nn.softmax_15[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_15 (Dropout)           (None, 15, 256)      0           ['multiply_15[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 256)         0           ['dropout_15[0][0]']             \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 4)            1028        ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 12,905,524\n",
      "Trainable params: 12,892,660\n",
      "Non-trainable params: 12,864\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Import Libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau, EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from models.resnet_A import build_resnet_with_attention\n",
    "from preprocessing.resnet_preprocessing import load_data, split_data  # Assuming you have a preprocessing script named data_preprocessing.py\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Cell 2: Load and Preprocess Data\n",
    "# Load the DWT-transformed data\n",
    "dwt_file_path = 'data/processed/dwt_features_ecg.csv'  # Update with the correct path\n",
    "data = pd.read_csv(dwt_file_path)\n",
    "\n",
    "# Extract features and labels\n",
    "X = data.iloc[:, :-1].values  # All columns except the last one are features\n",
    "y = data.iloc[:, -1].values  # Last column is the label\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)\n",
    "X_test = scaler.transform(X_test.reshape(-1, X_test.shape[-1])).reshape(X_test.shape)\n",
    "\n",
    "# One-hot encode labels\n",
    "num_classes = 4\n",
    "y_train_one_hot = tf.keras.utils.to_categorical(y_train, num_classes=num_classes)\n",
    "y_test_one_hot = tf.keras.utils.to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "# Reshape input data to match model expectations (batch_size, time_steps, num_features)\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Extract Time Step and Number of Features\n",
    "time_step = X_train.shape[1]\n",
    "num_features = X_train.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Build the Model\n",
    "\n",
    "# Build and compile the ResNet with attention model\n",
    "model = build_resnet_with_attention((time_step, num_features), num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 2026, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_48 (Conv1D)             (None, 2026, 32)     544         ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 2026, 32)    128         ['conv1d_48[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 2026, 32)     0           ['batch_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_49 (Conv1D)             (None, 2026, 32)     16416       ['activation_32[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_50 (Conv1D)             (None, 2026, 32)     64          ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 2026, 32)    128         ['conv1d_49[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 2026, 32)    128         ['conv1d_50[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_16 (Add)                   (None, 2026, 32)     0           ['batch_normalization_49[0][0]', \n",
      "                                                                  'batch_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 2026, 32)     0           ['add_16[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 2026, 1)      33          ['activation_33[0][0]']          \n",
      "                                                                                                  \n",
      " tf.nn.softmax_16 (TFOpLambda)  (None, 2026, 1)      0           ['dense_17[0][0]']               \n",
      "                                                                                                  \n",
      " multiply_16 (Multiply)         (None, 2026, 32)     0           ['activation_33[0][0]',          \n",
      "                                                                  'tf.nn.softmax_16[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_16 (Dropout)           (None, 2026, 32)     0           ['multiply_16[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_51 (Conv1D)             (None, 2026, 32)     16416       ['dropout_16[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 2026, 32)    128         ['conv1d_51[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 2026, 32)     0           ['batch_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_52 (Conv1D)             (None, 2026, 32)     16416       ['activation_34[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_53 (Conv1D)             (None, 2026, 32)     1056        ['dropout_16[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 2026, 32)    128         ['conv1d_52[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_53 (BatchN  (None, 2026, 32)    128         ['conv1d_53[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_17 (Add)                   (None, 2026, 32)     0           ['batch_normalization_52[0][0]', \n",
      "                                                                  'batch_normalization_53[0][0]'] \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 2026, 32)     0           ['add_17[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (None, 2026, 1)      33          ['activation_35[0][0]']          \n",
      "                                                                                                  \n",
      " tf.nn.softmax_17 (TFOpLambda)  (None, 2026, 1)      0           ['dense_18[0][0]']               \n",
      "                                                                                                  \n",
      " multiply_17 (Multiply)         (None, 2026, 32)     0           ['activation_35[0][0]',          \n",
      "                                                                  'tf.nn.softmax_17[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_17 (Dropout)           (None, 2026, 32)     0           ['multiply_17[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_54 (Conv1D)             (None, 2026, 32)     16416       ['dropout_17[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_54 (BatchN  (None, 2026, 32)    128         ['conv1d_54[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 2026, 32)     0           ['batch_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_55 (Conv1D)             (None, 2026, 32)     16416       ['activation_36[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_56 (Conv1D)             (None, 2026, 32)     1056        ['dropout_17[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_55 (BatchN  (None, 2026, 32)    128         ['conv1d_55[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_56 (BatchN  (None, 2026, 32)    128         ['conv1d_56[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_18 (Add)                   (None, 2026, 32)     0           ['batch_normalization_55[0][0]', \n",
      "                                                                  'batch_normalization_56[0][0]'] \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 2026, 32)     0           ['add_18[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 2026, 1)      33          ['activation_37[0][0]']          \n",
      "                                                                                                  \n",
      " tf.nn.softmax_18 (TFOpLambda)  (None, 2026, 1)      0           ['dense_19[0][0]']               \n",
      "                                                                                                  \n",
      " multiply_18 (Multiply)         (None, 2026, 32)     0           ['activation_37[0][0]',          \n",
      "                                                                  'tf.nn.softmax_18[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling1d_7 (MaxPooling1D)  (None, 1013, 32)    0           ['multiply_18[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_18 (Dropout)           (None, 1013, 32)     0           ['max_pooling1d_7[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_57 (Conv1D)             (None, 1013, 64)     32832       ['dropout_18[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_57 (BatchN  (None, 1013, 64)    256         ['conv1d_57[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (None, 1013, 64)     0           ['batch_normalization_57[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_58 (Conv1D)             (None, 1013, 64)     65600       ['activation_38[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_59 (Conv1D)             (None, 1013, 64)     2112        ['dropout_18[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_58 (BatchN  (None, 1013, 64)    256         ['conv1d_58[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_59 (BatchN  (None, 1013, 64)    256         ['conv1d_59[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_19 (Add)                   (None, 1013, 64)     0           ['batch_normalization_58[0][0]', \n",
      "                                                                  'batch_normalization_59[0][0]'] \n",
      "                                                                                                  \n",
      " activation_39 (Activation)     (None, 1013, 64)     0           ['add_19[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_20 (Dense)               (None, 1013, 1)      65          ['activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " tf.nn.softmax_19 (TFOpLambda)  (None, 1013, 1)      0           ['dense_20[0][0]']               \n",
      "                                                                                                  \n",
      " multiply_19 (Multiply)         (None, 1013, 64)     0           ['activation_39[0][0]',          \n",
      "                                                                  'tf.nn.softmax_19[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_19 (Dropout)           (None, 1013, 64)     0           ['multiply_19[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_60 (Conv1D)             (None, 1013, 64)     65600       ['dropout_19[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_60 (BatchN  (None, 1013, 64)    256         ['conv1d_60[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_40 (Activation)     (None, 1013, 64)     0           ['batch_normalization_60[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_61 (Conv1D)             (None, 1013, 64)     65600       ['activation_40[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_62 (Conv1D)             (None, 1013, 64)     4160        ['dropout_19[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_61 (BatchN  (None, 1013, 64)    256         ['conv1d_61[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_62 (BatchN  (None, 1013, 64)    256         ['conv1d_62[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_20 (Add)                   (None, 1013, 64)     0           ['batch_normalization_61[0][0]', \n",
      "                                                                  'batch_normalization_62[0][0]'] \n",
      "                                                                                                  \n",
      " activation_41 (Activation)     (None, 1013, 64)     0           ['add_20[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_21 (Dense)               (None, 1013, 1)      65          ['activation_41[0][0]']          \n",
      "                                                                                                  \n",
      " tf.nn.softmax_20 (TFOpLambda)  (None, 1013, 1)      0           ['dense_21[0][0]']               \n",
      "                                                                                                  \n",
      " multiply_20 (Multiply)         (None, 1013, 64)     0           ['activation_41[0][0]',          \n",
      "                                                                  'tf.nn.softmax_20[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling1d_8 (MaxPooling1D)  (None, 506, 64)     0           ['multiply_20[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_20 (Dropout)           (None, 506, 64)      0           ['max_pooling1d_8[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_63 (Conv1D)             (None, 506, 64)      65600       ['dropout_20[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_63 (BatchN  (None, 506, 64)     256         ['conv1d_63[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, 506, 64)      0           ['batch_normalization_63[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_64 (Conv1D)             (None, 506, 64)      65600       ['activation_42[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_65 (Conv1D)             (None, 506, 64)      4160        ['dropout_20[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_64 (BatchN  (None, 506, 64)     256         ['conv1d_64[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_65 (BatchN  (None, 506, 64)     256         ['conv1d_65[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_21 (Add)                   (None, 506, 64)      0           ['batch_normalization_64[0][0]', \n",
      "                                                                  'batch_normalization_65[0][0]'] \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, 506, 64)      0           ['add_21[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_22 (Dense)               (None, 506, 1)       65          ['activation_43[0][0]']          \n",
      "                                                                                                  \n",
      " tf.nn.softmax_21 (TFOpLambda)  (None, 506, 1)       0           ['dense_22[0][0]']               \n",
      "                                                                                                  \n",
      " multiply_21 (Multiply)         (None, 506, 64)      0           ['activation_43[0][0]',          \n",
      "                                                                  'tf.nn.softmax_21[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_21 (Dropout)           (None, 506, 64)      0           ['multiply_21[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_66 (Conv1D)             (None, 506, 64)      65600       ['dropout_21[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_66 (BatchN  (None, 506, 64)     256         ['conv1d_66[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, 506, 64)      0           ['batch_normalization_66[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_67 (Conv1D)             (None, 506, 64)      65600       ['activation_44[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_68 (Conv1D)             (None, 506, 64)      4160        ['dropout_21[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_67 (BatchN  (None, 506, 64)     256         ['conv1d_67[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_68 (BatchN  (None, 506, 64)     256         ['conv1d_68[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_22 (Add)                   (None, 506, 64)      0           ['batch_normalization_67[0][0]', \n",
      "                                                                  'batch_normalization_68[0][0]'] \n",
      "                                                                                                  \n",
      " activation_45 (Activation)     (None, 506, 64)      0           ['add_22[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_23 (Dense)               (None, 506, 1)       65          ['activation_45[0][0]']          \n",
      "                                                                                                  \n",
      " tf.nn.softmax_22 (TFOpLambda)  (None, 506, 1)       0           ['dense_23[0][0]']               \n",
      "                                                                                                  \n",
      " multiply_22 (Multiply)         (None, 506, 64)      0           ['activation_45[0][0]',          \n",
      "                                                                  'tf.nn.softmax_22[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling1d_9 (MaxPooling1D)  (None, 253, 64)     0           ['multiply_22[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_22 (Dropout)           (None, 253, 64)      0           ['max_pooling1d_9[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_69 (Conv1D)             (None, 253, 128)     131200      ['dropout_22[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_69 (BatchN  (None, 253, 128)    512         ['conv1d_69[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_46 (Activation)     (None, 253, 128)     0           ['batch_normalization_69[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_70 (Conv1D)             (None, 253, 128)     262272      ['activation_46[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_71 (Conv1D)             (None, 253, 128)     8320        ['dropout_22[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_70 (BatchN  (None, 253, 128)    512         ['conv1d_70[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_71 (BatchN  (None, 253, 128)    512         ['conv1d_71[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_23 (Add)                   (None, 253, 128)     0           ['batch_normalization_70[0][0]', \n",
      "                                                                  'batch_normalization_71[0][0]'] \n",
      "                                                                                                  \n",
      " activation_47 (Activation)     (None, 253, 128)     0           ['add_23[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_24 (Dense)               (None, 253, 1)       129         ['activation_47[0][0]']          \n",
      "                                                                                                  \n",
      " tf.nn.softmax_23 (TFOpLambda)  (None, 253, 1)       0           ['dense_24[0][0]']               \n",
      "                                                                                                  \n",
      " multiply_23 (Multiply)         (None, 253, 128)     0           ['activation_47[0][0]',          \n",
      "                                                                  'tf.nn.softmax_23[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_23 (Dropout)           (None, 253, 128)     0           ['multiply_23[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_72 (Conv1D)             (None, 253, 128)     262272      ['dropout_23[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_72 (BatchN  (None, 253, 128)    512         ['conv1d_72[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_48 (Activation)     (None, 253, 128)     0           ['batch_normalization_72[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_73 (Conv1D)             (None, 253, 128)     262272      ['activation_48[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_74 (Conv1D)             (None, 253, 128)     16512       ['dropout_23[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_73 (BatchN  (None, 253, 128)    512         ['conv1d_73[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_74 (BatchN  (None, 253, 128)    512         ['conv1d_74[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_24 (Add)                   (None, 253, 128)     0           ['batch_normalization_73[0][0]', \n",
      "                                                                  'batch_normalization_74[0][0]'] \n",
      "                                                                                                  \n",
      " activation_49 (Activation)     (None, 253, 128)     0           ['add_24[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_25 (Dense)               (None, 253, 1)       129         ['activation_49[0][0]']          \n",
      "                                                                                                  \n",
      " tf.nn.softmax_24 (TFOpLambda)  (None, 253, 1)       0           ['dense_25[0][0]']               \n",
      "                                                                                                  \n",
      " multiply_24 (Multiply)         (None, 253, 128)     0           ['activation_49[0][0]',          \n",
      "                                                                  'tf.nn.softmax_24[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling1d_10 (MaxPooling1D  (None, 126, 128)    0           ['multiply_24[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_24 (Dropout)           (None, 126, 128)     0           ['max_pooling1d_10[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d_75 (Conv1D)             (None, 126, 128)     262272      ['dropout_24[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_75 (BatchN  (None, 126, 128)    512         ['conv1d_75[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_50 (Activation)     (None, 126, 128)     0           ['batch_normalization_75[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_76 (Conv1D)             (None, 126, 128)     262272      ['activation_50[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_77 (Conv1D)             (None, 126, 128)     16512       ['dropout_24[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_76 (BatchN  (None, 126, 128)    512         ['conv1d_76[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_77 (BatchN  (None, 126, 128)    512         ['conv1d_77[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_25 (Add)                   (None, 126, 128)     0           ['batch_normalization_76[0][0]', \n",
      "                                                                  'batch_normalization_77[0][0]'] \n",
      "                                                                                                  \n",
      " activation_51 (Activation)     (None, 126, 128)     0           ['add_25[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_26 (Dense)               (None, 126, 1)       129         ['activation_51[0][0]']          \n",
      "                                                                                                  \n",
      " tf.nn.softmax_25 (TFOpLambda)  (None, 126, 1)       0           ['dense_26[0][0]']               \n",
      "                                                                                                  \n",
      " multiply_25 (Multiply)         (None, 126, 128)     0           ['activation_51[0][0]',          \n",
      "                                                                  'tf.nn.softmax_25[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_25 (Dropout)           (None, 126, 128)     0           ['multiply_25[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_78 (Conv1D)             (None, 126, 128)     262272      ['dropout_25[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_78 (BatchN  (None, 126, 128)    512         ['conv1d_78[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_52 (Activation)     (None, 126, 128)     0           ['batch_normalization_78[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_79 (Conv1D)             (None, 126, 128)     262272      ['activation_52[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_80 (Conv1D)             (None, 126, 128)     16512       ['dropout_25[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_79 (BatchN  (None, 126, 128)    512         ['conv1d_79[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_80 (BatchN  (None, 126, 128)    512         ['conv1d_80[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_26 (Add)                   (None, 126, 128)     0           ['batch_normalization_79[0][0]', \n",
      "                                                                  'batch_normalization_80[0][0]'] \n",
      "                                                                                                  \n",
      " activation_53 (Activation)     (None, 126, 128)     0           ['add_26[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_27 (Dense)               (None, 126, 1)       129         ['activation_53[0][0]']          \n",
      "                                                                                                  \n",
      " tf.nn.softmax_26 (TFOpLambda)  (None, 126, 1)       0           ['dense_27[0][0]']               \n",
      "                                                                                                  \n",
      " multiply_26 (Multiply)         (None, 126, 128)     0           ['activation_53[0][0]',          \n",
      "                                                                  'tf.nn.softmax_26[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling1d_11 (MaxPooling1D  (None, 63, 128)     0           ['multiply_26[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_26 (Dropout)           (None, 63, 128)      0           ['max_pooling1d_11[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d_81 (Conv1D)             (None, 63, 256)      524544      ['dropout_26[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_81 (BatchN  (None, 63, 256)     1024        ['conv1d_81[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_54 (Activation)     (None, 63, 256)      0           ['batch_normalization_81[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_82 (Conv1D)             (None, 63, 256)      1048832     ['activation_54[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_83 (Conv1D)             (None, 63, 256)      33024       ['dropout_26[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_82 (BatchN  (None, 63, 256)     1024        ['conv1d_82[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_83 (BatchN  (None, 63, 256)     1024        ['conv1d_83[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_27 (Add)                   (None, 63, 256)      0           ['batch_normalization_82[0][0]', \n",
      "                                                                  'batch_normalization_83[0][0]'] \n",
      "                                                                                                  \n",
      " activation_55 (Activation)     (None, 63, 256)      0           ['add_27[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_28 (Dense)               (None, 63, 1)        257         ['activation_55[0][0]']          \n",
      "                                                                                                  \n",
      " tf.nn.softmax_27 (TFOpLambda)  (None, 63, 1)        0           ['dense_28[0][0]']               \n",
      "                                                                                                  \n",
      " multiply_27 (Multiply)         (None, 63, 256)      0           ['activation_55[0][0]',          \n",
      "                                                                  'tf.nn.softmax_27[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_27 (Dropout)           (None, 63, 256)      0           ['multiply_27[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_84 (Conv1D)             (None, 63, 256)      1048832     ['dropout_27[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_84 (BatchN  (None, 63, 256)     1024        ['conv1d_84[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_56 (Activation)     (None, 63, 256)      0           ['batch_normalization_84[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_85 (Conv1D)             (None, 63, 256)      1048832     ['activation_56[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_86 (Conv1D)             (None, 63, 256)      65792       ['dropout_27[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_85 (BatchN  (None, 63, 256)     1024        ['conv1d_85[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_86 (BatchN  (None, 63, 256)     1024        ['conv1d_86[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_28 (Add)                   (None, 63, 256)      0           ['batch_normalization_85[0][0]', \n",
      "                                                                  'batch_normalization_86[0][0]'] \n",
      "                                                                                                  \n",
      " activation_57 (Activation)     (None, 63, 256)      0           ['add_28[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_29 (Dense)               (None, 63, 1)        257         ['activation_57[0][0]']          \n",
      "                                                                                                  \n",
      " tf.nn.softmax_28 (TFOpLambda)  (None, 63, 1)        0           ['dense_29[0][0]']               \n",
      "                                                                                                  \n",
      " multiply_28 (Multiply)         (None, 63, 256)      0           ['activation_57[0][0]',          \n",
      "                                                                  'tf.nn.softmax_28[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling1d_12 (MaxPooling1D  (None, 31, 256)     0           ['multiply_28[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_28 (Dropout)           (None, 31, 256)      0           ['max_pooling1d_12[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d_87 (Conv1D)             (None, 31, 256)      1048832     ['dropout_28[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_87 (BatchN  (None, 31, 256)     1024        ['conv1d_87[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_58 (Activation)     (None, 31, 256)      0           ['batch_normalization_87[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_88 (Conv1D)             (None, 31, 256)      1048832     ['activation_58[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_89 (Conv1D)             (None, 31, 256)      65792       ['dropout_28[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_88 (BatchN  (None, 31, 256)     1024        ['conv1d_88[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_89 (BatchN  (None, 31, 256)     1024        ['conv1d_89[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_29 (Add)                   (None, 31, 256)      0           ['batch_normalization_88[0][0]', \n",
      "                                                                  'batch_normalization_89[0][0]'] \n",
      "                                                                                                  \n",
      " activation_59 (Activation)     (None, 31, 256)      0           ['add_29[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_30 (Dense)               (None, 31, 1)        257         ['activation_59[0][0]']          \n",
      "                                                                                                  \n",
      " tf.nn.softmax_29 (TFOpLambda)  (None, 31, 1)        0           ['dense_30[0][0]']               \n",
      "                                                                                                  \n",
      " multiply_29 (Multiply)         (None, 31, 256)      0           ['activation_59[0][0]',          \n",
      "                                                                  'tf.nn.softmax_29[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_29 (Dropout)           (None, 31, 256)      0           ['multiply_29[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_90 (Conv1D)             (None, 31, 256)      1048832     ['dropout_29[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_90 (BatchN  (None, 31, 256)     1024        ['conv1d_90[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_60 (Activation)     (None, 31, 256)      0           ['batch_normalization_90[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_91 (Conv1D)             (None, 31, 256)      1048832     ['activation_60[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_92 (Conv1D)             (None, 31, 256)      65792       ['dropout_29[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_91 (BatchN  (None, 31, 256)     1024        ['conv1d_91[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_92 (BatchN  (None, 31, 256)     1024        ['conv1d_92[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_30 (Add)                   (None, 31, 256)      0           ['batch_normalization_91[0][0]', \n",
      "                                                                  'batch_normalization_92[0][0]'] \n",
      "                                                                                                  \n",
      " activation_61 (Activation)     (None, 31, 256)      0           ['add_30[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_31 (Dense)               (None, 31, 1)        257         ['activation_61[0][0]']          \n",
      "                                                                                                  \n",
      " tf.nn.softmax_30 (TFOpLambda)  (None, 31, 1)        0           ['dense_31[0][0]']               \n",
      "                                                                                                  \n",
      " multiply_30 (Multiply)         (None, 31, 256)      0           ['activation_61[0][0]',          \n",
      "                                                                  'tf.nn.softmax_30[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling1d_13 (MaxPooling1D  (None, 15, 256)     0           ['multiply_30[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_30 (Dropout)           (None, 15, 256)      0           ['max_pooling1d_13[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d_93 (Conv1D)             (None, 15, 256)      1048832     ['dropout_30[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_93 (BatchN  (None, 15, 256)     1024        ['conv1d_93[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_62 (Activation)     (None, 15, 256)      0           ['batch_normalization_93[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_94 (Conv1D)             (None, 15, 256)      1048832     ['activation_62[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_95 (Conv1D)             (None, 15, 256)      65792       ['dropout_30[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_94 (BatchN  (None, 15, 256)     1024        ['conv1d_94[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_95 (BatchN  (None, 15, 256)     1024        ['conv1d_95[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_31 (Add)                   (None, 15, 256)      0           ['batch_normalization_94[0][0]', \n",
      "                                                                  'batch_normalization_95[0][0]'] \n",
      "                                                                                                  \n",
      " activation_63 (Activation)     (None, 15, 256)      0           ['add_31[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_32 (Dense)               (None, 15, 1)        257         ['activation_63[0][0]']          \n",
      "                                                                                                  \n",
      " tf.nn.softmax_31 (TFOpLambda)  (None, 15, 1)        0           ['dense_32[0][0]']               \n",
      "                                                                                                  \n",
      " multiply_31 (Multiply)         (None, 15, 256)      0           ['activation_63[0][0]',          \n",
      "                                                                  'tf.nn.softmax_31[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_31 (Dropout)           (None, 15, 256)      0           ['multiply_31[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_1 (Gl  (None, 256)         0           ['dropout_31[0][0]']             \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " dense_33 (Dense)               (None, 4)            1028        ['global_average_pooling1d_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 12,905,524\n",
      "Trainable params: 12,892,660\n",
      "Non-trainable params: 12,864\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cell 5: Compile the Model\n",
    "# Define learning rate scheduler, TensorBoard, and ModelCheckpoint callbacks\n",
    "# Define callbacks\n",
    "log_dir = f\"logs/tensorboard/ResNet_DWT/{datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
    "checkpoint_callback = ModelCheckpoint(filepath='resnet_dwt_best_model.h5', save_best_only=True, verbose=1)\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-8)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "callbacks = [checkpoint_callback, tensorboard_callback, lr_scheduler, early_stopping]\n",
    "\n",
    "\n",
    "# Calculate class weights to handle class imbalance\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y), y=y)\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Display model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "427/427 [==============================] - ETA: 0s - loss: 1.5928 - accuracy: 0.3996\n",
      "Epoch 1: val_loss did not improve from 1.61422\n",
      "427/427 [==============================] - 40s 92ms/step - loss: 1.5928 - accuracy: 0.3996 - val_loss: 1.6914 - val_accuracy: 0.0287 - lr: 1.2500e-04\n",
      "Epoch 2/100\n",
      "427/427 [==============================] - ETA: 0s - loss: 1.5596 - accuracy: 0.2932\n",
      "Epoch 2: val_loss improved from 1.61422 to 1.59366, saving model to resnet_dwt_best_model.h5\n",
      "427/427 [==============================] - 39s 92ms/step - loss: 1.5596 - accuracy: 0.2932 - val_loss: 1.5937 - val_accuracy: 0.2696 - lr: 1.2500e-04\n",
      "Epoch 3/100\n",
      "427/427 [==============================] - ETA: 0s - loss: 1.5382 - accuracy: 0.2476\n",
      "Epoch 3: val_loss did not improve from 1.59366\n",
      "427/427 [==============================] - 39s 91ms/step - loss: 1.5382 - accuracy: 0.2476 - val_loss: 1.7105 - val_accuracy: 0.0287 - lr: 1.2500e-04\n",
      "Epoch 4/100\n",
      "427/427 [==============================] - ETA: 0s - loss: 1.4866 - accuracy: 0.2724\n",
      "Epoch 4: val_loss improved from 1.59366 to 1.51575, saving model to resnet_dwt_best_model.h5\n",
      "427/427 [==============================] - 39s 92ms/step - loss: 1.4866 - accuracy: 0.2724 - val_loss: 1.5157 - val_accuracy: 0.5674 - lr: 1.2500e-04\n",
      "Epoch 5/100\n",
      "427/427 [==============================] - ETA: 0s - loss: 1.4798 - accuracy: 0.5035\n",
      "Epoch 5: val_loss improved from 1.51575 to 1.43738, saving model to resnet_dwt_best_model.h5\n",
      "427/427 [==============================] - 39s 92ms/step - loss: 1.4798 - accuracy: 0.5035 - val_loss: 1.4374 - val_accuracy: 0.6102 - lr: 1.2500e-04\n",
      "Epoch 6/100\n",
      "427/427 [==============================] - ETA: 0s - loss: 1.4139 - accuracy: 0.3138\n",
      "Epoch 6: val_loss did not improve from 1.43738\n",
      "427/427 [==============================] - 39s 91ms/step - loss: 1.4139 - accuracy: 0.3138 - val_loss: 1.9564 - val_accuracy: 0.0487 - lr: 1.2500e-04\n",
      "Epoch 7/100\n",
      "427/427 [==============================] - ETA: 0s - loss: 1.4130 - accuracy: 0.2004\n",
      "Epoch 7: val_loss did not improve from 1.43738\n",
      "427/427 [==============================] - 40s 93ms/step - loss: 1.4130 - accuracy: 0.2004 - val_loss: 1.4720 - val_accuracy: 0.5914 - lr: 1.2500e-04\n",
      "Epoch 8/100\n",
      "427/427 [==============================] - ETA: 0s - loss: 1.4219 - accuracy: 0.2359\n",
      "Epoch 8: val_loss did not improve from 1.43738\n",
      "427/427 [==============================] - 40s 93ms/step - loss: 1.4219 - accuracy: 0.2359 - val_loss: 1.4980 - val_accuracy: 0.5844 - lr: 1.2500e-04\n",
      "Epoch 9/100\n",
      "427/427 [==============================] - ETA: 0s - loss: 1.4218 - accuracy: 0.2383\n",
      "Epoch 9: val_loss improved from 1.43738 to 1.43366, saving model to resnet_dwt_best_model.h5\n",
      "427/427 [==============================] - 40s 94ms/step - loss: 1.4218 - accuracy: 0.2383 - val_loss: 1.4337 - val_accuracy: 0.0944 - lr: 6.2500e-05\n",
      "Epoch 10/100\n",
      "427/427 [==============================] - ETA: 0s - loss: 1.3685 - accuracy: 0.1951\n",
      "Epoch 10: val_loss improved from 1.43366 to 1.37233, saving model to resnet_dwt_best_model.h5\n",
      "427/427 [==============================] - 40s 94ms/step - loss: 1.3685 - accuracy: 0.1951 - val_loss: 1.3723 - val_accuracy: 0.1026 - lr: 6.2500e-05\n",
      "Epoch 11/100\n",
      "427/427 [==============================] - ETA: 0s - loss: 1.3549 - accuracy: 0.2511\n",
      "Epoch 11: val_loss improved from 1.37233 to 1.37127, saving model to resnet_dwt_best_model.h5\n",
      "427/427 [==============================] - 40s 93ms/step - loss: 1.3549 - accuracy: 0.2511 - val_loss: 1.3713 - val_accuracy: 0.0856 - lr: 6.2500e-05\n",
      "Epoch 12/100\n",
      "427/427 [==============================] - ETA: 0s - loss: 1.3711 - accuracy: 0.2345\n",
      "Epoch 12: val_loss did not improve from 1.37127\n",
      "427/427 [==============================] - 39s 91ms/step - loss: 1.3711 - accuracy: 0.2345 - val_loss: 1.3955 - val_accuracy: 0.5821 - lr: 6.2500e-05\n",
      "Epoch 13/100\n",
      "139/427 [========>.....................] - ETA: 22s - loss: 1.3211 - accuracy: 0.1803"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Cell 6: Train the Model\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Train the model with class weights and callbacks\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_one_hot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test_one_hot\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\yashv\\.conda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\yashv\\.conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\yashv\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\yashv\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\yashv\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\yashv\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\yashv\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\yashv\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\yashv\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Cell 6: Train the Model\n",
    "\n",
    "# Train the model with class weights and callbacks\n",
    "history = model.fit(\n",
    "    X_train, y_train_one_hot,\n",
    "    validation_data=(X_test, y_test_one_hot),\n",
    "    epochs=100,\n",
    "    batch_size=16,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Evaluate the Model on the Test Set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test_one_hot, verbose=1)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Plot Training History\n",
    "# Plot accuracy and loss curves\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Accuracy\n",
    "ax1.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "ax1.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.set_title('Training and Validation Accuracy')\n",
    "ax1.legend()\n",
    "\n",
    "# Loss\n",
    "ax2.plot(history.history['loss'], label='Train Loss')\n",
    "ax2.plot(history.history['val_loss'], label='Validation Loss')\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.set_title('Training and Validation Loss')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Save the Model\n",
    "# Save the trained model for future use\n",
    "model.save('models/resnet_trained.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
