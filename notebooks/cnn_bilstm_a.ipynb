{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashv\\Downloads\\HADLN_implementation\\HADLN_implementation\n",
      "C:\\Users\\yashv\\Downloads\\HADLN_implementation\\HADLN_implementation\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Check current working directory\n",
    "print(os.getcwd())\n",
    "\n",
    "# Change to the root directory of your project, if necessary\n",
    "os.chdir('C:/Users/yashv/Downloads/HADLN_implementation/HADLN_implementation/')\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from datetime import datetime\n",
    "from preprocessing.lstm_preprocessing import load_data, split_data  # Update this import path as needed\n",
    "from models.cnn_bilstm_a import create_bi_lstm_model  # Import the LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split  # Import for splitting data\n",
    "\n",
    "# File paths\n",
    "csv_file_path = 'data/raw/physionet2017.csv'  # Update the path to your CSV file\n",
    "model_path = 'models/bilstm_A_best.h5'\n",
    "log_dir = f\"results/tensorboard/BiLSTMA/{datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# Load and prepare data\n",
    "# Ensure load_data function is defined properly\n",
    "ecg_signals, labels_one_hot, num_classes = load_data(csv_file_path)\n",
    "\n",
    "# Convert one-hot labels back to integer labels for class weights calculation\n",
    "labels_integer = np.argmax(labels_one_hot, axis=1)\n",
    "\n",
    "# Split data into training and testing sets (80% train, 20% test split)\n",
    "X_train, X_test, y_train_one_hot, y_test_one_hot = train_test_split(ecg_signals, labels_one_hot, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"bidirectional_5\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 2000)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m num_features \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]   \u001b[38;5;66;03m# Number of features (should be 1 after reshaping)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Build and compile the LSTM model\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_bi_lstm_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_classes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Define a learning rate scheduler\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ReduceLROnPlateau\n",
      "File \u001b[1;32m~\\Downloads\\HADLN_implementation\\HADLN_implementation\\models\\cnn_bilstm_a.py:45\u001b[0m, in \u001b[0;36mcreate_bi_lstm_model\u001b[1;34m(input_shape, lstm_units, dropout_rate, num_classes)\u001b[0m\n\u001b[0;32m     42\u001b[0m inputs \u001b[38;5;241m=\u001b[39m Input(shape\u001b[38;5;241m=\u001b[39minput_shape)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Bi-GRU layers with attention\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mBidirectional\u001b[49m\u001b[43m(\u001b[49m\u001b[43mGRU\u001b[49m\u001b[43m(\u001b[49m\u001b[43munits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m x \u001b[38;5;241m=\u001b[39m attention_block(x)\n\u001b[0;32m     47\u001b[0m x \u001b[38;5;241m=\u001b[39m Bidirectional(GRU(units\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))(x)\n",
      "File \u001b[1;32mc:\\Users\\yashv\\.conda\\envs\\tf\\lib\\site-packages\\keras\\layers\\rnn\\bidirectional.py:277\u001b[0m, in \u001b[0;36mBidirectional.__call__\u001b[1;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[0;32m    274\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m inputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m initial_state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m constants \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    279\u001b[0m \u001b[38;5;66;03m# Applies the same workaround as in `RNN.__call__`\u001b[39;00m\n\u001b[0;32m    280\u001b[0m additional_inputs \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\yashv\\.conda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\yashv\\.conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\input_spec.py:232\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    230\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m shape\u001b[38;5;241m.\u001b[39mrank\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ndim \u001b[38;5;241m!=\u001b[39m spec\u001b[38;5;241m.\u001b[39mndim:\n\u001b[1;32m--> 232\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    233\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    234\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis incompatible with the layer: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    235\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected ndim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, found ndim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    236\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFull shape received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(shape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    237\u001b[0m         )\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mmax_ndim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    239\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39mrank\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 of layer \"bidirectional_5\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 2000)"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))  # Adding a feature dimension\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Extract time_step and num_features\n",
    "time_step = X_train.shape[1]      # Number of time steps\n",
    "num_features = X_train.shape[2]   # Number of features (should be 1 after reshaping)\n",
    "\n",
    "# Build and compile the LSTM model\n",
    "model = create_bi_lstm_model(time_step, num_features, num_classes=num_classes)\n",
    "\n",
    "# Define a learning rate scheduler\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss',\n",
    "                                 factor=0.5,\n",
    "                                 patience=3,\n",
    "                                 min_lr=1e-8)\n",
    "\n",
    "# Compile the model\n",
    "from tensorflow_addons.losses import SigmoidFocalCrossEntropy\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss=SigmoidFocalCrossEntropy(),  # Focal Loss for imbalanced classes\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "checkpoint_callback = ModelCheckpoint(filepath=model_path, save_best_only=True, verbose=1)\n",
    "callbacks = [checkpoint_callback, tensorboard_callback, lr_scheduler]\n",
    "\n",
    "# Train the model with class weights and callbacks\n",
    "history = model.fit(X_train, y_train_one_hot,\n",
    "          validation_data=(X_test, y_test_one_hot),\n",
    "          epochs=100,\n",
    "          batch_size=32,\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "model_path = 'models/cnnbilstma_best.h5'  # Adjust path if necessary\n",
    "model = tf.keras.models.load_model(model_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
